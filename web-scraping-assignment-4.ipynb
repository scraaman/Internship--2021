{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9fde549",
   "metadata": {},
   "source": [
    "So, in these notebook we will scrape data from naukri.com website for\n",
    "data scientist job role and delhi location. we will scrape 4 fields for each job\n",
    ".1 title of the job 2 name of the company 3 location\n",
    "4 experience required\n",
    "\n",
    "Let me show all these fields on the naukri.com website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a516801e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from selenium) (1.26.4)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from selenium) (0.19.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (2.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.14.5)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: idna in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (3.4.7)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (20.0.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (2020.12.5)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "# Lets first install the selenium library\n",
    "!pip install selenium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e56c09",
   "metadata": {},
   "source": [
    "Now we will download the web driver for the web browser . the steps for downloading the web driver\n",
    "for ur browser are:\n",
    "    1. check the version of your browser\n",
    "    2. go to the link<chromedriver.chromium.org/downloads\n",
    "    3. download the web driver for your version of web browser\n",
    "    now these steps are for chrome browser. the download links will be different mozilla etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eafe9dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c20b2c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3973ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-953d381b69ca>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ffac7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "231bc714",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6341eea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-ad47a1337c2c>:2: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
      "<ipython-input-36-ad47a1337c2c>:4: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n"
     ]
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "search_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys(\"Delhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "306744a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-c9b437d84350>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n"
     ]
    }
   ],
   "source": [
    "search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d2afdb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the url of the webpage to be scrapped\n",
    "url = \"https://www.naukri.com/data-scientist-jobs-in-delhi?k=data%20scientist&l=delhi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61b624e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d3d9fb",
   "metadata": {},
   "source": [
    "Now we will see in the window opened by web driver whether the web page has opened or not.\n",
    "Lets check it\n",
    "\n",
    "\n",
    "so , Now lets first create 4 empty lists. In these lists the data will be stored while scraping. We have created 4 empty lists for 4 features which we have to extract\n",
    "\n",
    "1.job_titles 2.company_names 3. locations_list 4.experience_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "996c7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]\n",
    "company_names=[]\n",
    "locations_list=[]\n",
    "experience_list=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "95342d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-143-bd340fa092f8>:2: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"d9d9cee1-4e28-46a9-9877-1cf9348a812a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"2bd6f1ff-5424-4297-9420-5750c4701f70\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"0dd70219-3c89-48c7-97af-2d803cde4a3c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"8eb62bc1-d8c2-4389-8ba5-9a5b174cdeea\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"f63b85b0-35f5-4b2e-8373-c200d9688e1c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"802b8b79-f864-4aff-a4ef-5ad8d80106ca\")>]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so lets extract all the tags having the job-titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "titles_tags[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbbb5f3",
   "metadata": {},
   "source": [
    "Now we have all the tags in which there are job titles.\n",
    "\n",
    "Now we will extract the text from these tags one by one looping over these tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "97ceacee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist/Senior Data Scientist - IT Services Firm',\n",
       " 'Data Scientist: Advanced Analytics',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist / Machine Learning Engineer - Python / SQL / Spark',\n",
       " 'Data Scientist - Sales Analytics',\n",
       " 'Big Data Scientist']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the text of the job title is inside the tags extracted above.\n",
    "# so we will run a loop to iterate over the tags extracted above and extract \n",
    "\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_titles.append(title)\n",
    "job_titles[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00515ca8",
   "metadata": {},
   "source": [
    "Now we will extract all the html tags where we have the company names. Let me first show you in which tags the company names are put on the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8f9d9695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-141-95f8ab6482f2>:1: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"d2c2d46f-e392-431a-842d-4a73159be457\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"fd6974f3-4e50-4709-8c1a-ec951463fa0e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"afa77bf2-09e4-46ed-88f6-c40f5d81d651\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"d1133d56-a883-4ee2-b6cb-ad25f71f0413\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"1525fb2d-3c1f-487d-b6d6-b48387c0ed92\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"2cf79bb1-4530-410c-ac18-d5c6658822f4\")>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9e1bb",
   "metadata": {},
   "source": [
    "Now we have all the tags in which there are the company names.\n",
    "\n",
    "Now we will extract the text from these tags one by one by looping over these tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ad595ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pylon Management Consulting Pvt Ltd',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Stefanini',\n",
       " 'Axcess consultancy services',\n",
       " 'InnovAccer',\n",
       " 'Hire Hunters']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in companies_tags:\n",
    "    company_name=i.text\n",
    "    company_names.append(company_name)\n",
    "company_names[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4cd228",
   "metadata": {},
   "source": [
    "Now we will extract all the html tags where we have the experienced required data . Let me first show you in which tags this data is put on the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9358b41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-139-14eee02bf590>:2: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"73bfa57f-98cf-4172-a388-96cf012d2d81\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"fb16c4ff-e7fc-4678-b52b-188e32690b73\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"610e0500-22ab-4abc-808b-f537fac54f95\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"ae3429ef-7e1c-48d3-8a95-4ae6a98e0ab7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"8a455ad7-935d-4607-a3b1-19806c67c27e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"f76685cf-dbd8-4d99-8c93-86f44a4d88e6\")>]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so lets extract all the tags having the experience require data\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "experience_tags[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d661ce3",
   "metadata": {},
   "source": [
    "Now we have all the tags in which there is the experience required data.\n",
    "\n",
    "Now we will extract the text from these tags one by one by looping over these tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "276193c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5-6 Yrs', '2-5 Yrs', '5-10 Yrs', '3-8 Yrs', '4-9 Yrs', '5-10 Yrs']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in experience_tags:\n",
    "    experience=i.text\n",
    "    experience_list.append(experience)\n",
    "experience_list[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef9984b",
   "metadata": {},
   "source": [
    "Now we will extract all the html tags where we have the location of the job data. Let me first show you in which tags this data is put on the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ca75f68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-136-4a2c85ff1041>:1: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  locations_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"b7561cf5-d3ca-415e-aa4b-11600544ac96\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"5d443d8a-1af7-40d6-ac53-db46cfd28ea5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"82edba62-dac3-455f-aeea-180a42e11bf7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"b7876fb0-3f08-4692-908b-4b5e6ff8c68e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"9a06da0f-ce5a-462d-9656-d7bb13213f8a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9efbc1f07fe172072664f4ef26ad7eb1\", element=\"6e9b57b3-bf9d-4836-933f-33cae04ae0eb\")>]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "locations_tags[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d01ec2",
   "metadata": {},
   "source": [
    "Now we have all the tags in which there is a data about the location of the job.\n",
    "Now we will extract the text location from these tags one by one by looping over these tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ede0007e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Delhi / NCR',\n",
       " 'New Delhi',\n",
       " 'Hyderabad/Secunderabad, Pune, Chennai, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Noida, Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in locations_tags:\n",
    "    location=i.text\n",
    "    locations_list.append(location)\n",
    "locations_list[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de190d9",
   "metadata": {},
   "source": [
    "So,now we have extracted the data required from the webpage and stored them in the 6 lists mentioned above. Now before creating a dataframe from these lists. Lets first check the length of each of the list. Because if the length of the all the lists are not equal, then a dataframe cannot be formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "161244ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 120 40 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(company_names),len(experience_list),len(locations_list))\n",
    "                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c9a7b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles[0:6]\n",
    "jobs['company']=company_names[0:6]\n",
    "jobs['experience_required']=experience_list[0:6]\n",
    "jobs['location']=locations_list[0:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "96f319a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Senior Data Scientist - IT Serv...</td>\n",
       "      <td>Pylon Management Consulting Pvt Ltd</td>\n",
       "      <td>5-6 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Stefanini</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Machine Learning Engineer - P...</td>\n",
       "      <td>Axcess consultancy services</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Gurgaon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Sales Analytics</td>\n",
       "      <td>InnovAccer</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Big Data Scientist</td>\n",
       "      <td>Hire Hunters</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Data Scientist/Senior Data Scientist - IT Serv...   \n",
       "1                 Data Scientist: Advanced Analytics   \n",
       "2                                     Data Scientist   \n",
       "3  Data Scientist / Machine Learning Engineer - P...   \n",
       "4                   Data Scientist - Sales Analytics   \n",
       "5                                 Big Data Scientist   \n",
       "\n",
       "                               company experience_required  \\\n",
       "0  Pylon Management Consulting Pvt Ltd             5-6 Yrs   \n",
       "1               IBM India Pvt. Limited             2-5 Yrs   \n",
       "2                            Stefanini            5-10 Yrs   \n",
       "3          Axcess consultancy services             3-8 Yrs   \n",
       "4                           InnovAccer             4-9 Yrs   \n",
       "5                         Hire Hunters            5-10 Yrs   \n",
       "\n",
       "                                            location  \n",
       "0  Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...  \n",
       "1                                        Delhi / NCR  \n",
       "2                                          New Delhi  \n",
       "3  Hyderabad/Secunderabad, Pune, Chennai, Gurgaon...  \n",
       "4                         Noida, Bangalore/Bengaluru  \n",
       "5              Gurgaon/Gurugram, Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba157260",
   "metadata": {},
   "source": [
    "# ques 1 Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/ 2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b00ab9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from selenium) (1.26.4)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from selenium) (0.19.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (2.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.14.5)\n",
      "Requirement already satisfied: idna in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (3.4.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (2020.12.5)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (20.0.1)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e6c6c6",
   "metadata": {},
   "source": [
    "Now we will download the web driver for the web browser . the steps for downloading the web driver for ur browser are: 1. check the version of your browser 2. go to the link<chromedriver.chromium.org/downloads 3. download the web driver for your version of web browser now these steps are for chrome browser. the download links will be different mozilla etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8874e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b15b3b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cee6e814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-953d381b69ca>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4bcb798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "191a11a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eaef8859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-b9c9ff035903>:2: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
      "<ipython-input-42-b9c9ff035903>:4: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n"
     ]
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "search_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4966d13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-c9b437d84350>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n"
     ]
    }
   ],
   "source": [
    "search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "454fbb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the url of the webpage to be scrapped\n",
    "url = \"https://www.naukri.com/data-analyst-jobs-in-bangalore?k=data%20analyst&l=bangalore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "261621da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets open the webpage through our web driver\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a06786",
   "metadata": {},
   "source": [
    "Now we will see in the window opened by web driver whether the web page has opened or not. Lets check it\n",
    "\n",
    "so , Now lets first create 4 empty lists. In these lists the data will be stored while scraping. We have created 4 empty lists for 4 features which we have to extract\n",
    "\n",
    "1.job_titles 2.company_names 3. locations_list 4.experience_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0af0325",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]\n",
    "company_names=[]\n",
    "locations_list=[]\n",
    "experience_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bffc4316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-25d1a50c67c8>:2: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"c55fb793-143f-4114-b38b-0800efb7db98\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"b7cd438c-8f2c-4508-9bfd-e6eddd9e6cc2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"cbe378b4-f827-4854-8973-290a617f66d8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"0601d832-805c-4322-a172-899835851c87\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"b4527f1a-6c4c-4011-8639-9b01446c0f21\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"893a50ac-e7c1-46d9-931e-55995ad96590\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"0adab958-fca4-4a3a-988a-55a073b04ef8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"c2562433-b325-4357-bb85-e1063c1ed221\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"f9d4abc1-8009-4a87-990e-c3ba2cff6f6f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"289bbaf1-8c40-445c-a6f9-f351de7c64b8\")>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so lets extract all the tags having the job-titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "titles_tags[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222f94d7",
   "metadata": {},
   "source": [
    "Now we have all the tags in which there are job titles.\n",
    "\n",
    "Now we will extract the text from these tags one by one looping over these tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "170c149d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Analyst',\n",
       " 'Senior Data Analyst - FPG',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Business Data Analyst',\n",
       " 'Hero Vired - Data Analyst - Sales Strategy',\n",
       " 'Business Data Analyst - Database Design/Mining',\n",
       " 'Senior Data Analyst(Google Analytics)',\n",
       " 'SQL Data Analyst',\n",
       " 'Reporting & data Analyst role']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the text of the job title is inside the tags extracted above.\n",
    "# so we will run a loop to iterate over the tags extracted above and extract \n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_titles.append(title)\n",
    "job_titles[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c4fce",
   "metadata": {},
   "source": [
    "Now we will extract all the html tags where we have the company names. Let me first show you in which tags the company names are put on the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60ab246b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-53-e396278fca32>:1: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"7ed68d21-3d56-4241-8efd-90ae28b10ec7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"d6b17b4d-63a8-4005-8e99-1c07001bb7a8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"2666c095-849c-4e9a-90da-bc279d4bfb7d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"7ce249b2-6cb1-4e7d-ae1f-85c8331593d8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"08894c13-e013-4e6e-8017-818330412e78\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"ccc0f0ad-b1ef-4374-b166-f59eeea0397a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"e3e46035-53f1-4499-b570-66108e245168\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"8a835bce-f57e-47a0-b962-4c1f11ac55f0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"87bfaca9-3340-43eb-a408-c08853ae4db6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"ff33d686-8d4d-4b53-834e-082f8f491421\")>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f92223",
   "metadata": {},
   "source": [
    "Now we have all the tags in which there are the company names.\n",
    "\n",
    "Now we will extract the text from these tags one by one by looping over these tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b9d0121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IBM India Pvt. Limited',\n",
       " 'Flipkart',\n",
       " 'Flipkart',\n",
       " 'Flipkart',\n",
       " 'Tech Data Advanced Solutions India Pvt Ltd',\n",
       " 'HEROX PRIVATE LIMITED',\n",
       " 'AugmatrixGo',\n",
       " 'Cimpress India Private Limited',\n",
       " 'NetApp',\n",
       " 'EQUINITI INDIA PRIVATE LIMITED']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in companies_tags:\n",
    "    company_name=i.text\n",
    "    company_names.append(company_name)\n",
    "company_names[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c046a93f",
   "metadata": {},
   "source": [
    "Now we will extract all the html tags where we have the experienced required data . Let me first show you in which tags this data is put on the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ad45473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-9e79dabeee2f>:2: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"db4743fc-51f8-4203-8ede-0b8ba1106981\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"dcaa4e73-bbb2-499d-874d-c091b883f03e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"cf2daec1-227c-4f93-99c6-b0922c2f3a61\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"79213681-ea8b-426d-9b85-5413b1a34981\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"0ef76ee7-00eb-4edf-bca9-3bb645684355\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"872bae84-4a91-4b93-922a-aa49f65a2f53\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"723c0f56-5383-4c4b-82ce-174965a016ee\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"a2ca34a4-8299-4041-ab5b-0df9192534b7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"38111cf3-5267-461c-865f-098c47993d68\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"5d4fff33-568c-4714-924d-ea36d7bc4f2c\")>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so lets extract all the tags having the experience require data\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "experience_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "876b2063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-6 Yrs',\n",
       " '3-5 Yrs',\n",
       " '2-5 Yrs',\n",
       " '3-7 Yrs',\n",
       " '3-8 Yrs',\n",
       " '0-4 Yrs',\n",
       " '2-5 Yrs',\n",
       " '3-7 Yrs',\n",
       " '3-7 Yrs',\n",
       " '3-5 Yrs']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in experience_tags:\n",
    "    experience=i.text\n",
    "    experience_list.append(experience)\n",
    "experience_list[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcbf1b2",
   "metadata": {},
   "source": [
    "Now we will extract all the html tags where we have the location of the job data. Let me first show you in which tags this data is put on the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0cc57586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-c8f9297f4977>:1: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  locations_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"f968a9ac-ea78-4fcb-b435-04a803c442a4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"2d9deeeb-562b-4d3d-a168-82c2f6362499\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"b411b3fa-5127-4dd1-9700-46b9eb5d063b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"b1104f70-c496-433c-93db-71dcc14b5c54\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"d10403c8-724d-4a40-9528-6b6b72deeb2e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"79d25f00-f88d-45eb-a1f9-94afb9ee7e97\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"f44e1737-0c9e-42bc-be29-26e18fe331ef\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"1168a783-f555-438f-9cbf-7c72b8903f6f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"cfcc0310-7c02-42ba-9f1e-1da1b540de95\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"adf27ccba7c04be5fcfd4e67e5d84850\", element=\"1fc5dcbd-3f22-4c0a-b8f0-274e1632c361\")>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "locations_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02cbe3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Chennai, Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in locations_tags:\n",
    "    location=i.text\n",
    "    locations_list.append(location)\n",
    "locations_list[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d670cd02",
   "metadata": {},
   "source": [
    "So,now we have extracted the data required from the webpage and stored them in the 10 lists mentioned above. Now before creating a dataframe from these lists. Lets first check the length of each of the list. Because if the length of the all the lists are not equal, then a dataframe cannot be formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "21951a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(company_names),len(experience_list),len(locations_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cff25fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles[0:10]\n",
    "jobs['company']=company_names[0:10]\n",
    "jobs['experience_required']=experience_list[0:10]\n",
    "jobs['location']=locations_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d5b4d9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst - FPG</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Business Data Analyst</td>\n",
       "      <td>Tech Data Advanced Solutions India Pvt Ltd</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hero Vired - Data Analyst - Sales Strategy</td>\n",
       "      <td>HEROX PRIVATE LIMITED</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business Data Analyst - Database Design/Mining</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst(Google Analytics)</td>\n",
       "      <td>Cimpress India Private Limited</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SQL Data Analyst</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Reporting &amp; data Analyst role</td>\n",
       "      <td>EQUINITI INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title  \\\n",
       "0                             Senior Data Analyst   \n",
       "1                       Senior Data Analyst - FPG   \n",
       "2                             Senior Data Analyst   \n",
       "3                             Senior Data Analyst   \n",
       "4                    Senior Business Data Analyst   \n",
       "5      Hero Vired - Data Analyst - Sales Strategy   \n",
       "6  Business Data Analyst - Database Design/Mining   \n",
       "7           Senior Data Analyst(Google Analytics)   \n",
       "8                                SQL Data Analyst   \n",
       "9                   Reporting & data Analyst role   \n",
       "\n",
       "                                      company experience_required  \\\n",
       "0                      IBM India Pvt. Limited             3-6 Yrs   \n",
       "1                                    Flipkart             3-5 Yrs   \n",
       "2                                    Flipkart             2-5 Yrs   \n",
       "3                                    Flipkart             3-7 Yrs   \n",
       "4  Tech Data Advanced Solutions India Pvt Ltd             3-8 Yrs   \n",
       "5                       HEROX PRIVATE LIMITED             0-4 Yrs   \n",
       "6                                 AugmatrixGo             2-5 Yrs   \n",
       "7              Cimpress India Private Limited             3-7 Yrs   \n",
       "8                                      NetApp             3-7 Yrs   \n",
       "9              EQUINITI INDIA PRIVATE LIMITED             3-5 Yrs   \n",
       "\n",
       "                                  location  \n",
       "0                      Bengaluru/Bangalore  \n",
       "1                      Bangalore/Bengaluru  \n",
       "2                      Bangalore/Bengaluru  \n",
       "3                      Bangalore/Bengaluru  \n",
       "4  Bangalore/Bengaluru, Mumbai (All Areas)  \n",
       "5                      Bangalore/Bengaluru  \n",
       "6                      Bangalore/Bengaluru  \n",
       "7  Bangalore/Bengaluru, Mumbai (All Areas)  \n",
       "8                      Bangalore/Bengaluru  \n",
       "9             Chennai, Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b20c2d",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8301837c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from selenium) (0.19.0)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from selenium) (1.26.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Requirement already satisfied: idna in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (2.3.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (3.4.7)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (20.0.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (2020.12.5)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c2c36a",
   "metadata": {},
   "source": [
    "Now we will download the web driver for the web browser . the steps for downloading the web driver for ur browser are: 1. check the version of your browser 2. go to the link<chromedriver.chromium.org/downloads 3. download the web driver for your version of web browser now these steps are for chrome browser. the download links will be different mozilla etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9df39195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9c7788b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3471c5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-953d381b69ca>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "888ae681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2a37c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2c2fa6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-70-d76974ce92e0>:2: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
      "<ipython-input-70-d76974ce92e0>:4: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n"
     ]
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "search_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9cf2e44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-71-c9b437d84350>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n"
     ]
    }
   ],
   "source": [
    "search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d8052a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]\n",
    "company_names=[]\n",
    "locations_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a54cd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-73-25d1a50c67c8>:2: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"21434ccf-3de0-431f-9901-ecd87edd9654\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"b25969ae-d28a-4ea8-b968-b0b3a129e5a7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"e386587b-b31a-4c6f-82a9-c7c720a79c41\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"1b482233-46f2-4f2e-bd9e-1cf594bc9ff1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"abd79b09-8dd3-4cc0-ad58-57e38dd3f7e8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"4f549547-bf83-46d3-9ea3-f3ca333b0e0f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"963d5ad7-fd05-403f-b104-c19d6a0280a2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"f761eab1-95aa-46dc-9b57-c37fc47c5ace\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"d6b050f2-504e-4b89-bc1b-178f7a3c903b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"5bf22c84-1b50-426a-850f-45e5313d4799\")>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so lets extract all the tags having the job-titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "titles_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a991a865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Staff Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist: Advanced Analytics',\n",
       " 'Data Scientist: Advanced Analytics',\n",
       " 'Cognitive Data Scientist',\n",
       " 'Spark ML Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Lead Data Scientist',\n",
       " 'Senior Data Scientist']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the text of the job title is inside the tags extracted above.\n",
    "# so we will run a loop to iterate over the tags extracted above and extract \n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_titles.append(title)\n",
    "job_titles[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6b5b5469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-75-c8f9297f4977>:1: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  locations_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"79ae4043-bb9d-4fe5-9a85-cc5dda84ad53\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"ed7fa097-01d6-4c3c-9ee7-c94f1b11801e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"bcecbea4-b48d-40ef-82b1-32b8dfd06648\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"01966179-3ce9-4454-af29-7d7ba23c0d9f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"b0afca2b-acf3-4147-aa05-f2953b002418\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"beb71736-41e1-4115-9d61-149884465309\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"25329e74-6a22-40b6-8b0c-d0664811228a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"e1bbe347-a344-48d1-b32d-9c5ac6979cb4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"a4967e0e-551a-4590-8c7d-dee4fb6fe238\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"3d5b0cfb-0a2c-478c-a414-5c1e0763d769\")>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "locations_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b5d5251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Pune',\n",
       " '(WFH during Covid)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in locations_tags:\n",
    "    location=i.text\n",
    "    locations_list.append(location)\n",
    "locations_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7c4092a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-77-e396278fca32>:1: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"117d4590-2006-41f0-8ed4-059e1bd04e30\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"aa4d7cc5-4d85-4e88-a2f7-e33aec108fb3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"1392668b-3841-4cac-8a48-d8f696dda0a1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"aed8413c-58ef-4474-925a-f50889eac8e8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"74eedf39-cdf8-42e5-895a-8c28b2ef3425\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"11a5fc55-ad4a-4949-afba-9a7178677624\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"9b5910d4-5d01-4217-b831-b6a6983c36ac\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"9a564aa7-660c-4539-a546-330bdfc02502\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"1aeba8d6-bb38-41a4-aad8-1ea517b79958\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"7204579e7f9b1dd2f15139097fccd368\", element=\"a07e09ab-4a48-4a34-acec-346ade709e60\")>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0dfd3507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Swiggy',\n",
       " 'Flipkart',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Wipro',\n",
       " 'Philips India Limited',\n",
       " 'Minions Ventures',\n",
       " 'Perform Group',\n",
       " 'IBM India Pvt. Limited']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in companies_tags:\n",
    "    company_name=i.text\n",
    "    company_names.append(company_name)\n",
    "company_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "205e50df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 21\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(company_names),len(locations_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "196a4474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles[0:10]\n",
    "jobs['location']=locations_list[0:10]\n",
    "jobs['company']=company_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5e546277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Staff Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Swiggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cognitive Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spark ML Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>Philips India Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Minions Ventures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Perform Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title                   location  \\\n",
       "0         Senior Staff Data Scientist        Bangalore/Bengaluru   \n",
       "1                      Data Scientist        Bangalore/Bengaluru   \n",
       "2  Data Scientist: Advanced Analytics        Bangalore/Bengaluru   \n",
       "3  Data Scientist: Advanced Analytics        Bangalore/Bengaluru   \n",
       "4            Cognitive Data Scientist        Bangalore/Bengaluru   \n",
       "5             Spark ML Data Scientist  Bangalore/Bengaluru, Pune   \n",
       "6                      Data Scientist         (WFH during Covid)   \n",
       "7                      Data Scientist        Bangalore/Bengaluru   \n",
       "8                 Lead Data Scientist        Bangalore/Bengaluru   \n",
       "9               Senior Data Scientist        Bangalore/Bengaluru   \n",
       "\n",
       "                  company  \n",
       "0                  Swiggy  \n",
       "1                Flipkart  \n",
       "2  IBM India Pvt. Limited  \n",
       "3  IBM India Pvt. Limited  \n",
       "4  IBM India Pvt. Limited  \n",
       "5                   Wipro  \n",
       "6   Philips India Limited  \n",
       "7        Minions Ventures  \n",
       "8           Perform Group  \n",
       "9  IBM India Pvt. Limited  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f777d3e",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f64cf5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from selenium) (1.26.4)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from selenium) (0.19.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (2.3.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.14.5)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (20.0.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (2020.12.5)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (3.4.7)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\ashok kumar chaurasi\\videos\\anaconda python\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0dc88",
   "metadata": {},
   "source": [
    "Now we will download the web driver for the web browser . the steps for downloading the web driver for ur browser are: 1. check the version of your browser 2. go to the link<chromedriver.chromium.org/downloads 3. download the web driver for your version of web browser now these steps are for chrome browser. the download links will be different mozilla etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "78a1a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "99d60e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7364ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-86-953d381b69ca>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "920fd773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "81272e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55f6f792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-89-cc9de372015c>:2: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n"
     ]
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5dad1169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-90-c9b437d84350>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n"
     ]
    }
   ],
   "source": [
    "search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6b33bca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-91-c8f9297f4977>:1: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  locations_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"314c8b388a8872b18b20af154437b112\", element=\"90a1e006-74b5-420e-8345-c98b3630f141\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"314c8b388a8872b18b20af154437b112\", element=\"1937a672-176d-4c79-9112-b8e34d343854\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"314c8b388a8872b18b20af154437b112\", element=\"e1457151-4a24-4055-931e-14ad1293cbb6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"314c8b388a8872b18b20af154437b112\", element=\"37e2cddb-9554-48b8-a894-cb27e329fc18\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"314c8b388a8872b18b20af154437b112\", element=\"51357fa9-525f-4a35-a54b-152f2dcbadfa\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"314c8b388a8872b18b20af154437b112\", element=\"9bd9a7a8-0416-4d4d-9805-bbdaf527c76f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"314c8b388a8872b18b20af154437b112\", element=\"e562f20d-e732-46b4-85ed-40691ea5afd9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"314c8b388a8872b18b20af154437b112\", element=\"356f45af-280a-4cd8-9773-ce565fba34da\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"314c8b388a8872b18b20af154437b112\", element=\"17bc8d44-fe2b-4621-93ed-9fc84042ee20\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"314c8b388a8872b18b20af154437b112\", element=\"5d92b620-b079-40f0-897d-2adf379ca96f\")>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "locations_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "80901082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Pune',\n",
       " '(WFH during Covid)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in locations_tags:\n",
    "    location=i.text\n",
    "    locations_list.append(location)\n",
    "locations_list[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7eecb7",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”.You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1c3a2df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6ed7f7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-94-b07bd7825bd2>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    }
   ],
   "source": [
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)\n",
    "# driver.close()\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2ae2addf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-95-75e32890c0f1>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  salaries_btn = driver.find_element_by_xpath(\"//a[@class='link salaries']\")\n"
     ]
    }
   ],
   "source": [
    "salaries_btn = driver.find_element_by_xpath(\"//a[@class='link salaries']\")\n",
    "salaries_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "204def21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-96-15502b65fa14>:2: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_job = driver.find_element_by_id(\"jobProfileSearchbox\")\n"
     ]
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_job = driver.find_element_by_id(\"jobProfileSearchbox\")\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "679e34f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-99-579918e9ddb0>:2: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  experience_tags=driver.find_elements_by_xpath(\"//div[@class='salaries sbold-list-header']\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"dba8aee62b36d9e26b610471e4d959cf\", element=\"2827dc33-f9c8-4bc5-8672-df79d7804f60\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"dba8aee62b36d9e26b610471e4d959cf\", element=\"83f4ebd6-f758-4112-8c99-92b913858cec\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"dba8aee62b36d9e26b610471e4d959cf\", element=\"fb1553bb-c992-4977-b382-7b52c3f784ed\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"dba8aee62b36d9e26b610471e4d959cf\", element=\"fc66d767-3ef7-4915-a56a-2dab3f6e6dff\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"dba8aee62b36d9e26b610471e4d959cf\", element=\"579b286b-68d1-4d59-922f-6b1d44988054\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"dba8aee62b36d9e26b610471e4d959cf\", element=\"eb44f8a5-bc84-42f1-be33-ce3fefc22443\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"dba8aee62b36d9e26b610471e4d959cf\", element=\"cda8e6b4-e508-42c9-a868-6409ce16afe9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"dba8aee62b36d9e26b610471e4d959cf\", element=\"834955f4-8002-4478-9a23-2c8cfd780dc9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"dba8aee62b36d9e26b610471e4d959cf\", element=\"adec255a-4667-4c96-8419-ff54c89cf7f8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"dba8aee62b36d9e26b610471e4d959cf\", element=\"bf1690ab-bb2a-43b5-b40d-1e53c6600ad0\")>]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so lets extract all the tags having the experience require data\n",
    "experience_tags=driver.find_elements_by_xpath(\"//div[@class='salaries sbold-list-header']\")\n",
    "experience_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d1296413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-6 Yrs',\n",
       " '3-5 Yrs',\n",
       " '2-5 Yrs',\n",
       " '3-7 Yrs',\n",
       " '3-8 Yrs',\n",
       " '0-4 Yrs',\n",
       " '2-5 Yrs',\n",
       " '3-7 Yrs',\n",
       " '3-7 Yrs',\n",
       " '3-5 Yrs']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in experience_tags:\n",
    "    experience=i.text\n",
    "    experience_list.append(experience)\n",
    "experience_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a39dc479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ddd7da6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-102-b07bd7825bd2>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    }
   ],
   "source": [
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)\n",
    "# driver.close()\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c813ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "27e63c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "19533446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-107-cc4504603044>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    }
   ],
   "source": [
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)\n",
    "# driver.close()\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2d86fad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-108-5b4abf483b9e>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_job = driver.find_element_by_id(\"twotabsearchtextbox\")\n"
     ]
    }
   ],
   "source": [
    "search_job = driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search_job.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b63edee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-0c2bdf4a81a3>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_btn = driver.find_element_by_xpath(\"//input[@id='nav-search-submit-button']\")\n"
     ]
    }
   ],
   "source": [
    "search_btn = driver.find_element_by_xpath(\"//input[@id='nav-search-submit-button']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3a323cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/s?k=Laptop&ref=nb_sb_noss_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9fccde58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-111-dda6e274d84c>:2: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n"
     ]
    }
   ],
   "source": [
    "# locating the core i7 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "946a47ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-112-d0a8cabab279>:2: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n"
     ]
    }
   ],
   "source": [
    "# locating the core i9 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d9031",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        driver.find_elements_by_xpath(\"//ul[@class='a-pagination']/li[8]\").click()\n",
    "    except:\n",
    "        driver.find_elements_by_xpath(\"//ul[@class='a-pagination']/li[7]\").click()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ed0c1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "748683a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-115-70a4fae9be05>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    }
   ],
   "source": [
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)\n",
    "# driver.close()\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "076d739b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-116-f9a1bdc8fe15>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_job = driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n"
     ]
    }
   ],
   "source": [
    "search_job = driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search_job.send_keys(\"sunglases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "75198400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-117-8dc99695f07f>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_btn = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n"
     ]
    }
   ],
   "source": [
    "search_btn = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "71384800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-120-38b38c379b6b>:1: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  scrape_data=driver.find_elements_by_xpath(\"//a[@class='ge-49M _2Kfbh8']\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"3a5472bb53e540cf69531a80aafec2d1\", element=\"d1728286-57df-4347-ba32-1ee41e09e7ba\")>]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_data=driver.find_elements_by_xpath(\"//a[@class='ge-49M _2Kfbh8']\")\n",
    "scrape_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a2d3e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c4baf351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-123-70a4fae9be05>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    }
   ],
   "source": [
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)\n",
    "# driver.close()\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "16206110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-124-473c88beff4e>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_job = driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n"
     ]
    }
   ],
   "source": [
    "search_job = driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search_job.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5ace4981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-125-8dc99695f07f>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_btn = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n"
     ]
    }
   ],
   "source": [
    "search_btn = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "86f98393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9c67f676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-127-8b955656cba8>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    }
   ],
   "source": [
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)\n",
    "# driver.close()\n",
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb65e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
